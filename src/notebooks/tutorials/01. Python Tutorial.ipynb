{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "EUwqU6GTb0M1GO0KJBbTUr",
     "report_properties": {
      "rowId": "1238XBMAzEjdffWstfvBrn"
     },
     "type": "MD"
    }
   },
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "3qauGkoC58if2xa49BXwpN",
     "report_properties": {
      "rowId": "jxOfvge42m3RKXEq6UvPgw"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# importing module\n",
    "import requests\n",
    "import datetime, time\n",
    "\n",
    "def download_file(src, dest):\n",
    "    \"\"\"\n",
    "Function to dowload file(s) to a specified location\n",
    "Returns a dictionary object stating details like source, destination, started date time, end date time and timetaken.\n",
    "Arguments:\n",
    "src - Location from which file needs to be downloaded\n",
    "dest - Location at which file needs to be saved\n",
    "    \"\"\"\n",
    "    started_on = datetime.datetime.now()\n",
    "    start_time = time.perf_counter()\n",
    "    status = None\n",
    "    description = None\n",
    "    try:\n",
    "        response = requests.get(src)\n",
    "        open(f\"{dest}\", \"wb\").write(response.content)\n",
    "        status = \"Success\"\n",
    "    except Exception as e:\n",
    "        status = \"Fail\"\n",
    "        description = str(e)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    ended_on = datetime.datetime.now()\n",
    "\n",
    "    return {\n",
    "        \"source\": src,\n",
    "        \"destination\": dest,\n",
    "        \"started_on\": started_on,\n",
    "        \"completed_on\": ended_on,\n",
    "        \"time_taken\": (end_time - start_time),\n",
    "        \"status\": status,\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "kuBtaIhEFOa5yWEpkaDZJW",
     "report_properties": {
      "rowId": "Xa9Zgac4NpwqeLppJXdIVj"
     },
     "type": "MD"
    }
   },
   "source": [
    "## Logging\n",
    "> Tracking events i.e. errors, exceptions, warnings, informations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Vc4rIp3jOnv4u21jJg7Lyh",
     "report_properties": {
      "rowId": "IubYFqXesmQqxSF6QTQcTl"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Its a Warning\n",
      "ERROR:root:Did you try to divide by zero\n",
      "CRITICAL:root:Internet is down\n"
     ]
    }
   ],
   "source": [
    "# importing module\n",
    "import logging\n",
    "\n",
    "# Test messages\n",
    "logging.debug(\"Harmless debug Message\")\n",
    "logging.info(\"Just an information\")\n",
    "logging.warning(\"Its a Warning\")\n",
    "logging.error(\"Did you try to divide by zero\")\n",
    "logging.critical(\"Internet is down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "TdoigafnvozbqTCj6Tus8z",
     "report_properties": {
      "rowId": "0h2MJmq10Z7rPHPlpUsAse"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21-Jul-2025 10:50:56 [WARNING ] Python Language: Its a Warning\n",
      "WARNING:Python Language:Its a Warning\n",
      "21-Jul-2025 10:50:56 [ERROR   ] Python Language: Did you try to divide by zero\n",
      "ERROR:Python Language:Did you try to divide by zero\n",
      "21-Jul-2025 10:50:56 [CRITICAL] Python Language: Internet is down\n",
      "CRITICAL:Python Language:Internet is down\n"
     ]
    }
   ],
   "source": [
    "#logging.basicConfig(format='%(asctime)s %(levelname)-10s %(message)s')\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s [%(levelname)-8s] %(name)-12s: %(message)s', datefmt='%d-%b-%Y %H:%M:%S')\n",
    "console.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(\"Python Language\")\n",
    "\n",
    "logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(console)\n",
    "\n",
    "logger.debug(\"Harmless debug Message\")\n",
    "logger.info(\"Just an information\")\n",
    "logger.warning(\"Its a Warning\")\n",
    "logger.error(\"Did you try to divide by zero\")\n",
    "logger.critical(\"Internet is down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "IegTxPDcvV355ko52Bw6DK",
     "report_properties": {
      "rowId": "Ee1ES0qaVICSo49S9m4uTZ"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "LIST_SIZE = 50\n",
    "URLs = [\"https://picsum.photos/3000/3000\" for i in range(LIST_SIZE)]\n",
    "PATHS = [f\"files/output/images/img_{i}.jpeg\" for i in range(LIST_SIZE)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "F9rGRgERpELsnKaLFAZq7N",
     "report_properties": {
      "rowId": "zk60Y2QcW7AMrvFeVw9LiQ"
     },
     "type": "MD"
    }
   },
   "source": [
    "## Threading and Multiprocessing\n",
    " - Techniques to achive concurrency and parallelism\n",
    " - running and managing the multiple computations at the same time.\n",
    " - deals lot of things simultaneously.\n",
    " - debugging is very hard\n",
    "\n",
    "### Concurrency\n",
    " - achieved through the interleaving operation of processes on the central processing unit(CPU) or in other words by the context switching\n",
    " - can be done by using a single processing unit\n",
    " - increases the amount of work finished at a time\n",
    " - non-deterministic control flow approach\n",
    "\n",
    "### Parallelism\n",
    " - achieved by through multiple central processing units(CPUs)\n",
    " - needs multiple processing units\n",
    " - improves the throughput and computational speed of the system\n",
    " - deterministic control flow approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "zc6iVw4Ke1YbfH6XfWZWlR",
     "report_properties": {
      "rowId": "fXZcXIdFdnS0TZLs3WDx5J"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Threading\n",
    " - Implements the Concurrency\n",
    " - IO-bound tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "cPpevFW9kZ7xUt6JzJIyej",
     "report_properties": {
      "rowId": "b5r2dSML51DJx3UKaSGKDM"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def simple_threading():\n",
    "    t1 = threading.Thread(target=download_file, args=[URLs[0], \"files/thread_1.jpeg\"])\n",
    "    t2 = threading.Thread(target=download_file, args=[URLs[0], \"files/thread_2.jpeg\"])\n",
    "    t3 = threading.Thread(target=download_file, args=[URLs[0], \"files/thread_3.jpeg\"])\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "\n",
    "def thread_pooling():\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(download_file, URLs[0:3], PATHS[0:3])\n",
    "        for result in results:\n",
    "            logger.info(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "dUfqPkyZv6XF7w8WVlPVNo",
     "report_properties": {
      "rowId": "PYRUafRIAkSZiPBZOS7KER"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Aug-2023 04:59:03 [INFO    ] root        : {'source': 'https://picsum.photos/3000/3000', 'destination': 'files/img_0.jpeg', 'started_on': datetime.datetime(2023, 8, 24, 4, 59, 0, 593273), 'completed_on': datetime.datetime(2023, 8, 24, 4, 59, 3, 102773), 'time_taken': 2.509490514999925, 'status': 'Success', 'description': None}\n",
      "24-Aug-2023 04:59:04 [INFO    ] root        : {'source': 'https://picsum.photos/3000/3000', 'destination': 'files/img_1.jpeg', 'started_on': datetime.datetime(2023, 8, 24, 4, 59, 0, 595235), 'completed_on': datetime.datetime(2023, 8, 24, 4, 59, 4, 443243), 'time_taken': 3.8479987010000514, 'status': 'Success', 'description': None}\n",
      "24-Aug-2023 04:59:04 [INFO    ] root        : {'source': 'https://picsum.photos/3000/3000', 'destination': 'files/img_2.jpeg', 'started_on': datetime.datetime(2023, 8, 24, 4, 59, 0, 597096), 'completed_on': datetime.datetime(2023, 8, 24, 4, 59, 4, 177603), 'time_taken': 3.5804985459999443, 'status': 'Success', 'description': None}\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "thread_pooling()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "5RlyvpXA5dZ8ntchKR79xT",
     "report_properties": {
      "rowId": "LsEO3LCz6e9DDNEw7PemFE"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Multiprocessing\n",
    " - Implements the Parallelism\n",
    " - CPU bound Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "GafJVt9egGixyZBMN3mr9j",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def simple_processes():\n",
    "    t1 = multiprocessing.Process(target=downloadFile, args=[URLs[0], \"files/process_1.jpeg\"])\n",
    "    t2 = multiprocessing.Process(target=downloadFile, args=[URLs[0], \"files/process_2.jpeg\"])\n",
    "    t3 = multiprocessing.Process(target=downloadFile, args=[URLs[0], \"files/process_3.jpeg\"])\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "\n",
    "def multi_process():\n",
    "    process_list = []\n",
    "    for i in range(LIST_SIZE):\n",
    "        p = multiprocessing.Process(target=downloadFile, args=[URLs[i], PATHS[i]])\n",
    "        p.start()\n",
    "        process_list.append(p)\n",
    "    for p in process_list:\n",
    "        p.join()\n",
    "\n",
    "def process_pool():\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(downloadFile, URLs, PATHS)\n",
    "        for result in results:\n",
    "            print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "NuYBNzn2BJqVLN4lPvwi0O",
     "report_properties": {
      "rowId": "ovmO3Fc0GIKm2UUIcVd2wr"
     },
     "type": "MD"
    }
   },
   "source": [
    "# Numpy\n",
    "- Open source and fundamental package or library for **scientific computing** for Python\n",
    "- Contains multidimensional array and matrix data structures\n",
    "- Core of the scientific Python and PyData ecosystems\n",
    "- Universal standard for working with numerical data in Python\n",
    "- NumPy arrays are **faster** and more **compact** than Python lists\n",
    "- The core of the NumPy package is the **ndarray** object\n",
    "- Operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation\n",
    "- used extensively in Pandas, SciPy, Matplotlib, scikit-learn, scikit-image and most other data science and scientific Python packages\n",
    "\n",
    "## Reason for Fast\n",
    "1. Vectorization\n",
    "    - describes the absence of any explicit looping, indexing, etc.\n",
    "    - more concise and easier to read\n",
    "    - fewer lines of code generally means fewer bugs\n",
    "    - closely resembles standard mathematical notation\n",
    "2. Broadcasting\n",
    "    - describe the implicit element-by-element behavior of operations\n",
    "    - the smaller array is “broadcast” across the larger array so that they have compatible shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "hYdNFUCfGU1t4W2yj5Kx4T",
     "report_properties": {
      "rowId": "i5SXC3b78tl7qZg99EwEM2"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "VJY0BaPq5a3MjKUHGPNlEm",
     "report_properties": {
      "rowId": "MMN0GviqOF4uECKlr5yTIJ"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "#formatter = logging.Formatter('%(asctime)s [%(levelname)-8s] [%(processName)s] %(name)s: %(message)s', datefmt='%d-%b-%Y %H:%M:%S')\n",
    "formatter = logging.Formatter('[%(levelname)-8s]: %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(\"Numpy Library\")\n",
    "\n",
    "logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(console)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "NgR3IwaUFnjxEgizOWSk4j",
     "report_properties": {
      "rowId": "Lu2vw3szZXH8nLeLFSq2B8"
     },
     "type": "MD"
    }
   },
   "source": [
    "## Numpy Fundamentals\n",
    "Concepts, design decisions, and technical constraints in NumPy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "WYOEolFF9GPfi2WvjILEw6",
     "report_properties": {
      "rowId": "MAikTzptrxQ3uoAJ89Spz1"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Array Creation\n",
    "There are 6 general mechanisms for creating arrays:\n",
    "\n",
    "1. Conversion from other Python structures (i.e. lists and tuples)\n",
    "2. Intrinsic NumPy array creation functions (e.g. arange, ones, zeros, etc.)\n",
    "3. Replicating, joining, or mutating existing arrays\n",
    "4. Reading arrays from disk, either from standard or custom formats\n",
    "5. Creating arrays from raw bytes through the use of strings or buffers\n",
    "6. Use of special library functions (e.g., random)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "4KnVm40MYtvNcvAmEcOmF0",
     "report_properties": {
      "rowId": "GZ0ARw4HbEqEGphI1txfFU"
     },
     "type": "MD"
    }
   },
   "source": [
    "**Note:-** \n",
    "1. Naming Conventions:\n",
    "    1. \\*1D\\* : One Dimension Array\n",
    "    2. \\*2D\\* : Two Dimension Array\n",
    "    3. \\*3D\\* : Three Dimension Array\n",
    "    4. \\*nD\\* : n Dimension Array\n",
    "2. A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "SKW2Vd0ndJQllbrORjHYPJ",
     "report_properties": {
      "rowId": "i7AMtPcA5HyhUL7etyybOd"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Add defination for the functions used in single line for basic understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "iP2WfSNoihrb3q5BTr7zwh",
     "report_properties": {
      "rowId": "T2MkfnkkWPzPTAecY9CUFB"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Conversion from other Python structures (i.e. lists and tuples)\n",
    "l1D = np.array([1, 2, 3, 4])\n",
    "l2D = np.array([[1, 2], [3, 4]])\n",
    "l3D = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "t1D = np.array((1, 2, 3, 4), dtype=np.int8)\n",
    "\n",
    "# Intrinsic NumPy array creation functions (e.g. arange, ones, zeros, etc.)\n",
    "## arrange function: \n",
    "a1D_1 = np.arange(10)\n",
    "a1D_2 = np.arange(2, 10, dtype=float)\n",
    "a1D_3 = np.arange(2, 3, 0.1)\n",
    "## linspace function: \n",
    "l1d_4 = np.linspace(1., 10., 6)\n",
    "\n",
    "## eye function: \n",
    "e2D_1 = np.eye(3)\n",
    "e2D_2 = np.eye(3, 2)\n",
    "\n",
    "## diag function: \n",
    "d2D_1 = np.diag([1, 2, 3])\n",
    "d2D_2 = np.diag([1, 2, 3], 1)\n",
    "d2D_3 = np.diag(l2D)\n",
    "\n",
    "## vander function: \n",
    "v2D_1 = np.vander([1, 2, 3, 4], 2)\n",
    "v2D_2 = np.vander((1, 2, 3, 4), 4)\n",
    "v2D_3 = np.vander(np.linspace(0, 2, 5), 2)\n",
    "\n",
    "## zeros function:\n",
    "z3D_1 = np.zeros((2, 3))\n",
    "z3D_1 = np.zeros((2, 3, 2))\n",
    "\n",
    "## ones function:\n",
    "o3D_1 = np.ones((2, 3))\n",
    "o3D_1 = np.ones((2, 3, 2))\n",
    "\n",
    "## numpy.random.default_rng().random() function:\n",
    "dr3D_1 = np.random.default_rng(42).random((2, 3))\n",
    "dr3D_1 = np.random.default_rng(42).random((2, 3, 2))\n",
    "\n",
    "## indices function:\n",
    "n3D_1 = np.indices((3,3))\n",
    "\n",
    "# Replicating, joining, or mutating existing arrays\n",
    "## function:\n",
    "## function:\n",
    "\n",
    "# Reading arrays from disk, either from standard or custom formats\n",
    "## loadtxt function:\n",
    "\n",
    "# Creating arrays from raw bytes through the use of strings or buffers\n",
    "## fromfile function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "ofqxmo9fFNAlJCmOZlEuGv",
     "report_properties": {
      "rowId": "XhSVY9k89icA0MEI2baIKy"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ]: a1D_1: [0 1 2 3 4 5 6 7 8 9]\n",
      "[INFO    ]: a1D_2: [2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "[INFO    ]: e2D_1: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# TODO Call all the variables using logger\n",
    "logger.info(f\"a1D_1: {a1D_1}\")\n",
    "logger.info(f\"a1D_2: {a1D_2}\")\n",
    "logger.info(f\"e2D_1: {e2D_1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "NRJGQYHNViqP9qI3alHYBV",
     "report_properties": {
      "rowId": "RsosnZcGOf6u5fM76I8NA3"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "fuFhemd2XIcxJt41jqR8GK",
     "report_properties": {
      "rowId": "Gsja9FhpJX1BEpMB5Dcnt4"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "lPDklrVocVyn1HtWWAlVI0",
     "report_properties": {
      "rowId": "DL7dUwb3VJ4FesT9NOsZRY"
     },
     "type": "MD"
    }
   },
   "source": [
    "### I/O Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "vcVC1YqK62kgShaPMehJxz",
     "report_properties": {
      "rowId": "XrfUCNoyTlXPvqeWIc77kC"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "k91PGKr2mfFNqhmqGxlgUi",
     "report_properties": {
      "rowId": "LA7FzBs2Apxr0VagdZXX7Z"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Data Types\n",
    "| **Numpy type**             | **C type**                                                        | **Description**                                                                                  |\n",
    "|----------------------------|-------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| numpy.bool_                | bool                                                              | Boolean (True or False) stored as a byte                                                         |\n",
    "| numpy.byte                 | signed char                                                       | Platform-defined                                                                                 |\n",
    "| numpy.ubyte                | unsigned char                                                     | Platform-defined                                                                                 |\n",
    "| numpy.short                | short                                                             | Platform-defined                                                                                 |\n",
    "| numpy.ushort               | unsigned short                                                    | Platform-defined                                                                                 |\n",
    "| numpy.intc                 | int                                                               | Platform-defined                                                                                 |\n",
    "| numpy.uintc                | unsigned int                                                      | Platform-defined                                                                                 |\n",
    "| numpy.int_                 | long                                                              | Platform-defined                                                                                 |\n",
    "| numpy.uint                 | unsigned long                                                     | Platform-defined                                                                                 |\n",
    "| numpy.longlong             | long long                                                         | Platform-defined                                                                                 |\n",
    "| numpy.ulonglong            | unsigned long long                                                | Platform-defined                                                                                 |\n",
    "| numpy.half / numpy.float16| | Half precision float: sign bit, 5 bits exponent, 10 bits mantissa |\n",
    "| numpy.single               | float                                                             | Platform-defined single precision float: typically sign bit, 8 bits exponent, 23 bits mantissa   |\n",
    "| numpy.double               | double                                                            | Platform-defined double precision float: typically sign bit, 11 bits exponent, 52 bits mantissa. |\n",
    "| numpy.longdouble           | long double                                                       | Platform-defined extended-precision float                                                        |\n",
    "| numpy.csingle              | float complex                                                     | Complex number, represented by two single-precision floats (real and imaginary components)       |\n",
    "| numpy.cdouble              | double complex                                                    | Complex number, represented by two double-precision floats (real and imaginary components).      |\n",
    "| numpy.clongdouble          | long double complex                                               | Complex number, represented by two extended-precision floats (real and imaginary components).    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "d6F1f5q28HV6r7NxajYJik",
     "report_properties": {
      "rowId": "E8DKTx4OqxLYirvCvBqlb7"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "wNoP4unm1HoAP3zALjE0v0",
     "report_properties": {
      "rowId": "Wt8oQE1v2DRFvfF5ggsck3"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "D4TodsrfdLmtN2JCkMp3Or",
     "report_properties": {
      "rowId": "Z5HnhT1fbHTisjCSBLhS7P"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "SL5ky4VWiT3eTWkEm3NTD1",
     "report_properties": {
      "rowId": "IIaPX2dwrL951i4i1ZbBs7"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Copies and Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "uWM7MX3tD5FZbRSAJS9MDh",
     "report_properties": {
      "rowId": "iJFwWL0p0Ybxu4l7hJKKiL"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#code "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "q1Ovsm0UYV8qWFinnLrPqg",
     "report_properties": {
      "rowId": "yVa2skCFJbcLmmOCtz2bNS"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Structured arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "UumZDjZ0r7vSm3LwgnpUzE",
     "report_properties": {
      "rowId": "4qv32ATesxAozSAJm7ZlIm"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "cJqTZxlNqPRdnVQxkxmri7",
     "report_properties": {
      "rowId": "72Mwm6POH73NPgMBTj44jU"
     },
     "type": "MD"
    }
   },
   "source": [
    "### Universal functions (ufunc) basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "UZMnB0zBdbGTpzrqj2pYEP",
     "report_properties": {
      "rowId": "F0ti29NbyWvTZtTQGCAGCR"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "74AQyIIhh3MQd59svZl8uX",
     "report_properties": {
      "rowId": "edpRcISmOfSDtDUWeLbG0N"
     },
     "type": "MD"
    }
   },
   "source": [
    "# Pandas\n",
    "- data manipulation package for tabular data\n",
    "- used throughout the data analysis workflow\n",
    "- data can be imported from databases, spreadsheets, comma-separated values (CSV) files, and more.\n",
    "- High performance merging and joining of data\n",
    "- Data alignment and integrated handling of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "3idmYojPhgONgBMKrtzXKl",
     "report_properties": {
      "rowId": "0ONY4kH8jFTB8Vmx0N8LQT"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "0p7192QnhkzyoQcbDpGZY4",
     "report_properties": {
      "rowId": "pUQaouZRRS4iA9uBWlXNMI"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "#formatter = logging.Formatter('%(asctime)s [%(levelname)-8s] [%(processName)s] %(name)s: %(message)s', datefmt='%d-%b-%Y %H:%M:%S')\n",
    "formatter = logging.Formatter('[%(levelname)-8s]: %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(\"Pandas Library\")\n",
    "\n",
    "logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(console)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "IKg6rCJfhVdU7Sbfa2s7xQ",
     "report_properties": {
      "rowId": "xWUyvSMjWJy1RL3Lbz9kuv"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "## Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "p7gFTw73F7r5vwtKJnLIrG",
     "report_properties": {
      "rowId": "oBqVOp6Y41enFzk8lHKNdK"
     },
     "type": "MD"
    }
   },
   "source": [
    "# Practise Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "sGCznF17PMJhJ4h9yL8BKS",
     "report_properties": {
      "rowId": "ZiJNvLCLSnSTHRtfZjT4xw"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "WzgE46TQmrCq8v6AZZa4gK",
     "report_properties": {
      "rowId": "d4GxnMuLMonIFe4icu8lDx"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "console = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s [%(levelname)-8s] [%(processName)s] %(name)s: %(message)s', \\\n",
    "                              datefmt='%d-%b-%Y %H:%M:%S')\n",
    "console.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(\"Python Exercises\")\n",
    "\n",
    "logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(console)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "w7CpdsXOJtIxuuCezxJsXG",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def get_file_paths(src, extension = None, mindepth = 1, maxdepth = float('inf')):\n",
    "    rootdir = os.path.normcase(src)\n",
    "    file_paths = []\n",
    "    root_depth = rootdir.rstrip(os.path.sep).count(os.path.sep) - 1\n",
    "    for dirpath, dirs, files in os.walk(rootdir):\n",
    "        depth = dirpath.count(os.path.sep) - root_depth\n",
    "        if mindepth <= depth <= maxdepth:\n",
    "            for filename in files:\n",
    "                if extension is None:\n",
    "                    file_paths.append(os.path.join(dirpath, filename))\n",
    "                if os.path.splitext(filename)[1] == extension:\n",
    "                    file_paths.append(os.path.join(dirpath, filename))\n",
    "        elif depth > maxdepth:\n",
    "            del dirs[:] \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "1iqow6w5PQ6hmxTTEy3voA",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def get_file_names(paths):\n",
    "    urls = []\n",
    "    if type(paths) is str:\n",
    "        urls.append(paths)\n",
    "    if type(paths) is list:\n",
    "        urls = paths\n",
    "    \n",
    "    file_names = [url.split(os.path.sep)[-1] for url in urls]\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "xzupMTe1jC1W0YmSYtrGMy",
     "report_properties": {
      "rowId": "pbHsYSVYb9OsPAIN2NYYyg"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 1 - Downloading Files\n",
    "\n",
    "**Objective: -** Downlaod files using the below urls and Unzip those files\n",
    "\n",
    "Urls:-\n",
    "```\n",
    "   \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2018_Q4.zip\",\n",
    "    \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q1.zip\",\n",
    "    \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q2.zip\",\n",
    "    \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q3.zip\",\n",
    "    \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q4.zip\",\n",
    "    \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2020_Q1.zip\",\n",
    "    \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2220_Q1.zip\",\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "fl2iQ96B5wiYzKss0VgO3x",
     "report_properties": {
      "rowId": "uOjs0hfgX1vAJ0eK7HfVnu"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def download_and_unzip_file(src, dest):\n",
    "    log = {\n",
    "        \"source\": src,\n",
    "        \"destination\": dest,\n",
    "        \"started_on\": datetime.datetime.now(),\n",
    "        \"completed_on\": None,\n",
    "        \"time_taken\": -1,\n",
    "        \"status\": \"Failed\",\n",
    "        \"description\": \"UnKnown\"\n",
    "    }\n",
    "    start = time.perf_counter()\n",
    "    # noinspection PyBroadException\n",
    "    try:\n",
    "        response = requests.get(src)\n",
    "        ZipFile(BytesIO(response.content)).extractall(dest)\n",
    "        log[\"status\"] = \"Successful\".upper()\n",
    "        log[\"description\"] = \"Successfully extracted files\"\n",
    "    except Exception:\n",
    "        log[\"status\"] = \"Failed\".upper()\n",
    "        log[\"description\"] = traceback.format_exc()\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    log[\"time_taken\"] = (end - start)\n",
    "    log[\"completed_on\"] = datetime.datetime.now()\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "dhqwP157JdxODVKLLDzeld",
     "report_properties": {
      "rowId": "OrG113fbX8lCeS2xbyIWu7"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def unzip_files(urls):\n",
    "    paths = [\"files/output/url_extracted/\" for _ in range(len(urls))]\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(download_and_unzip_file, urls, paths)\n",
    "        for result in results:\n",
    "            logger.info(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "aAsNSgvNZH8Tuq2690DAgg",
     "report_properties": {
      "rowId": "gckEC9ueW3f2Z6yqKG8JCc"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def execute_download():\n",
    "    urls = [\"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2018_Q4.zip\",\n",
    "            \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q1.zip\",\n",
    "            \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q2.zip\",\n",
    "            \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q3.zip\",\n",
    "            \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q4.zip\",\n",
    "            \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2020_Q1.zip\",\n",
    "            \"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2220_Q1.zip\"]\n",
    "    unzip_files(urls)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "CGTxr1SlBrscRwdWuSGbcP",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Aug-2023 13:02:19 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2018_Q4.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 10, 946903), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 19, 883040), 'time_taken': 8.936083748999977, 'status': 'SUCCESSFUL', 'description': 'Successfully extracted files'}\n",
      "28-Aug-2023 13:02:19 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q1.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 10, 951345), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 13, 317890), 'time_taken': 2.3664954299999863, 'status': 'SUCCESSFUL', 'description': 'Successfully extracted files'}\n",
      "28-Aug-2023 13:02:19 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q2.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 13, 320174), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 18, 5446), 'time_taken': 4.685257428, 'status': 'SUCCESSFUL', 'description': 'Successfully extracted files'}\n",
      "28-Aug-2023 13:02:25 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q3.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 18, 9087), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 25, 871438), 'time_taken': 7.862338804000046, 'status': 'SUCCESSFUL', 'description': 'Successfully extracted files'}\n",
      "28-Aug-2023 13:02:25 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q4.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 19, 890101), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 23, 520946), 'time_taken': 3.630831055000044, 'status': 'SUCCESSFUL', 'description': 'Successfully extracted files'}\n",
      "28-Aug-2023 13:02:27 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2020_Q1.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 23, 523581), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 27, 474174), 'time_taken': 3.9505815570000777, 'status': 'SUCCESSFUL', 'description': 'Successfully extracted files'}\n",
      "28-Aug-2023 13:02:27 [INFO    ] [MainProcess] Python Exercises: {'source': 'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2220_Q1.zip', 'destination': 'files/output/url_extracted/', 'started_on': datetime.datetime(2023, 8, 28, 13, 2, 25, 875410), 'completed_on': datetime.datetime(2023, 8, 28, 13, 2, 26, 265680), 'time_taken': 0.3902607600000465, 'status': 'FAILED', 'description': 'Traceback (most recent call last):\\n  File \"<ipython-input-7-64445280030e>\", line 15, in download_and_unzip_file\\n    ZipFile(BytesIO(response.content)).extractall(dest)\\n  File \"/opt/python/lib/python3.8/zipfile.py\", line 1269, in __init__\\n    self._RealGetContents()\\n  File \"/opt/python/lib/python3.8/zipfile.py\", line 1336, in _RealGetContents\\n    raise BadZipFile(\"File is not a zip file\")\\nzipfile.BadZipFile: File is not a zip file\\n'}\n"
     ]
    }
   ],
   "source": [
    "# execute_download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "DHXRS6PmQaTho50jmJ937V",
     "report_properties": {
      "rowId": "MQfIgrzQGGOaHA3Ortf0Td"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 2 - Scraping\n",
    "\n",
    "**Objective: -** You need to download a file of weather data from a government website.\n",
    "files that are sitting at the following specified location.\n",
    "\n",
    "https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/\n",
    "\n",
    "You are looking for the file that was `Last Modified` on `2022-02-07 14:03`, you\n",
    "can't cheat and lookup the file number yourself. You must use Python to scrape\n",
    "this webpage, finding the corresponding file-name for this timestamp, `2022-02-07 14:03`\n",
    "\n",
    "Once you have obtained the correct file, and downloaded it, you must load the file\n",
    "into `Pandas` and find the record(s) with the highest `HourlyDryBulbTemperature`.\n",
    "Print these record(s) to the command line.\n",
    "\n",
    "Generally, your script should do the following ...\n",
    "1. Attempt to web scrap/pull down the contents of `https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/`\n",
    "2. Analyze it's structure, determine how to find the corresponding file to `2022-02-07 14:03` using Python.\n",
    "3. Build the `URL` required to download this file, and write the file locally.\n",
    "4. Open the file with `Pandas` and find the records with the highest `HourlyDryBulbTemperature`.\n",
    "5. Print this to stdout/command line/terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "tQcF1thgg3dXzAnpefcKSI",
     "report_properties": {
      "rowId": "mLlTtDs6sXU1ahtOPubvZX"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_weather_page():\n",
    "    url = \"https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "mW7nJcPWPLhlrUGKJZiShI",
     "report_properties": {
      "rowId": "PbWJLpRTtrXr0I95gNJgwd"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 3 - Convert JSON to CSV + Ragged Directories\n",
    "\n",
    "**Objective: -** Your task is two use `Python` to find all the `json` files located in the `files/input/json` folder.\n",
    "Once you find them all, read them with `Python` and convert them to `csv` files, to do this\n",
    "you will have to flatten out some of the nested `json` data structures.\n",
    "\n",
    "For example there is a `{\"type\":\"Point\",\"coordinates\":[-99.9,16.88333]}` that must flattened.\n",
    "\n",
    "Generally, your script should do the following ...\n",
    "1. Crawl the `files/input/json` directory with `Python` and identify all the `json` files.\n",
    "2. Load all the `json` files.\n",
    "3. Flatten out the `json` data structure.\n",
    "4. Write the results to a `csv` file, one for one with the json file, including the header names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "6X3TEuOjqeR2wUZXZZLdlb",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Usgdad4vGjGYBFrhj4Kfkl",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def process_json_to_csv(src, dest):\n",
    "    log = {\n",
    "        \"source\": src,\n",
    "        \"destination\": dest,\n",
    "        \"started_on\": datetime.datetime.now(),\n",
    "        \"completed_on\": None,\n",
    "        \"time_taken\": -1,\n",
    "        \"status\": \"Failed\",\n",
    "        \"description\": \"UnKnown\"\n",
    "    }\n",
    "    start = time.perf_counter()\n",
    "    # noinspection PyBroadException\n",
    "    try:\n",
    "        # code to read JSON, flatten the JSON data, and write as CSV\n",
    "        with open(os.path.normcase(src)) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            futures = []\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                for s_json_data in json_data:\n",
    "                    futures.append(executor.submit(flatten_json, s_json_data))\n",
    "                results = [r.result() for r in concurrent.futures.as_completed(futures)]\n",
    "                with open(dest, 'w', newline='\\n', encoding='utf-8') as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
    "                    writer.writeheader()\n",
    "                    writer.writerows(results)\n",
    "        log[\"status\"] = \"Successful\".upper()\n",
    "        log[\"description\"] = \"Successfully converted to CSV from JSON\"\n",
    "    except Exception:\n",
    "        log[\"status\"] = \"Failed\".upper()\n",
    "        log[\"description\"] = traceback.format_exc()\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    log[\"time_taken\"] = (end - start)\n",
    "    log[\"completed_on\"] = datetime.datetime.now()\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "zRPGyQ4wanbWdM7ZrD4gP1",
     "report_properties": {
      "rowId": "aVSlzNn5zah2kAw6KgGFco"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def convert_json_to_csv():\n",
    "    file_paths = get_file_paths(\"files/input/jsons\", extension=\".json\")\n",
    "    #file_names = get_file_names(file_paths)\n",
    "    output_file_paths = [\"files/output/csvs/\" + file_name + \".csv\" for file_name in get_file_names(file_paths)]\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(process_json_to_csv, file_paths, output_file_paths)\n",
    "        for result in results:\n",
    "            logger.info(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "wlBIvPEqLJN1XdgIOeE4MR",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'><class 'dict'>  22\n",
      "\n",
      "<class 'dict'> 2\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_csv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "NCpV2oVHZFXQYlRdaPJrJd",
     "report_properties": {
      "rowId": "n6s22WcKB9GI6guwmWM7ME"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 4 - Data Modeling\n",
    "\n",
    "**Objective: -** There are also\n",
    "3 `csv` files located in 'files/input/csvs' folder. Open each one and examine it, the \n",
    "first task is to create a `sql` script with the `DDL` to hold\n",
    "a `CREATE` statement for each data file. Remember to think about data types. \n",
    "Also, this `CREATE` statements should include indexes for each table, as well\n",
    "as primary and foreign keys.\n",
    "\n",
    "After you have finished this `sql` scripts, we must connect to `Postgres` using the `Python` package\n",
    "called `psycopg2`. Once connected we will run our `sql` scripts against the database.\n",
    "\n",
    "Finally, we will use `psycopg2` to insert the data in each `csv` file into the table you created.\n",
    "\n",
    "Generally, your script should do the following ...\n",
    "1. Examine each `csv` file in `files/input/csvs` folder. Design a `CREATE` statement for each file.\n",
    "2. Ensure you have indexes, primary and forgein keys.\n",
    "3. Use `psycopg2` to connect to `Postgres` on `localhost` and the default `port`.\n",
    "4. Create the tables against the database.\n",
    "5. Ingest the `csv` files into the tables you created, also using `psycopg2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "cDZhhprB9NYepQZ2AFudaj",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# inspect data types for the given files\n",
    "def inspect_data_types():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "N9T7YuBdZXiAsymAtDSnFD",
     "report_properties": {
      "rowId": "Vf5UH6z9rrqflZb9Tx3CBx"
     },
     "sql_cell_properties": {
      "sandboxMode": false,
      "variableName": "df_1"
     },
     "type": "SQL"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE abc (\n",
    "    id bigint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "dJSSfK4z4DWBg2llFukpWT",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def write_data_to_db():\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "PSyG5CYJJO95eDjuz6TfjA",
     "report_properties": {
      "rowId": "6xM5OJf7TOnEYzctxnxgCA"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 5 - Numpy - Analyzing Exam Scores\n",
    "\n",
    "**Objective: -** Important NumPy topics i.e. array creation, broadcasting, statistical calculations, and indexing.\n",
    "\n",
    "In this exercise:\n",
    "\n",
    "1. create a NumPy array of exam scores.\n",
    "1. calculate the mean and standard deviation of the scores.\n",
    "1. use boolean indexing to identify students who scored above the mean.\n",
    "1. calculate the percentage of students who scored above the mean.\n",
    "1. replace the lowest score with the mean score.\n",
    "1. calculate the score range using the difference between the maximum and minimum scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "1DgS9uvSyZ9Y0NcCMZa7CH",
     "report_properties": {
      "rowId": "bKu9mortZx4umeRxdLeAxz"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def exam_score_analysis():\n",
    "    # create a array\n",
    "    scores = np.array([85, 92, 78, 88, 95, 90, 82, 70, 92, 87])\n",
    "    \n",
    "    # 1. Calculate the mean and standard deviation of the scores\n",
    "    mean_score = np.mean(scores)\n",
    "    std_deviation = np.std(scores)\n",
    "    \n",
    "    # 2. Identify students who scored above the mean score\n",
    "    above_mean = scores > mean_score\n",
    "\n",
    "    # 3. Calculate the percentage of students who scored above the mean\n",
    "    above_mean_percentage = np.mean(above_mean) * 100\n",
    "\n",
    "    # 4. Replace the lowest score with the mean score\n",
    "    lowest_index = np.argmin(scores)\n",
    "    scores[lowest_index] = mean_score\n",
    "\n",
    "    # 5. Calculate the score range (maximum - minimum)\n",
    "    score_range = np.max(scores) - np.min(scores)\n",
    "    \n",
    "    logger.info(\"Mean Score: %f\", mean_score)\n",
    "    logger.info(\"Standard Deviation:  %f\", std_deviation)\n",
    "    logger.info(\"Percentage Above Mean:  %f\", above_mean_percentage)\n",
    "    logger.info(\"Updated Scores:  %s\", scores)\n",
    "    logger.info(\"Score Range:  %f\", score_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "X7JgQmcbKYv2QTo2pbJ4BW",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Aug-2023 13:02:35 [INFO    ] [MainProcess] Python Exercises: Mean Score: 85.900000\n",
      "28-Aug-2023 13:02:35 [INFO    ] [MainProcess] Python Exercises: Standard Deviation:  7.147727\n",
      "28-Aug-2023 13:02:35 [INFO    ] [MainProcess] Python Exercises: Percentage Above Mean:  60.000000\n",
      "28-Aug-2023 13:02:35 [INFO    ] [MainProcess] Python Exercises: Updated Scores:  [85 92 78 88 95 90 82 85 92 87]\n",
      "28-Aug-2023 13:02:35 [INFO    ] [MainProcess] Python Exercises: Score Range:  17.000000\n"
     ]
    }
   ],
   "source": [
    "# exam_score_analysis()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "YBT4ddo6yDf4eLRk8KCrxW",
     "report_properties": {
      "rowId": "yFK36oKR9lB37OxPQCLJiY"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 6 - Pandas\n",
    "\n",
    "**Objective: -** \n",
    "\n",
    "- DataFrame Basic Properties\n",
    "    1. No. of observations\n",
    "    2. No. of variables(columns)\n",
    "    3. No. of missing values\n",
    "- Cleaning Data\n",
    "    4. Rename columns having space with `_`\n",
    "    5. Create Columns\n",
    "        1. \n",
    "    6. Remove Column\n",
    "    7. Treat Missing Data\n",
    "- Filtering Data\n",
    "    8.  \n",
    "- Calculating From Data \n",
    "    9. \n",
    "- Grouping Data\n",
    "    10. \n",
    "- Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "O9xmt4R7Hyn6ldcCUQzhD1",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def data_analysis():\n",
    "    # Create Dataframe\n",
    "    df = pd.read_csv(\"files/input/csvs/sales/*\")\n",
    "    \n",
    "    logger.info(df.info())\n",
    "\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "vC8MVSM9C6DH4RcxV99W2A",
     "report_properties": {
      "rowId": "Pw4QwL7vaEHVoHizdrZKww"
     },
     "type": "MD"
    }
   },
   "source": [
    "#### Exercise 7 - Data Visualization\n",
    "\n",
    "**Objective: -** "
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "report_tabs": [
    {
     "id": "9N4ha5DLuVNwyypsg6akhP",
     "name": "Report tab",
     "rows": [
      "1238XBMAzEjdffWstfvBrn",
      "jxOfvge42m3RKXEq6UvPgw",
      "Xa9Zgac4NpwqeLppJXdIVj",
      "IubYFqXesmQqxSF6QTQcTl",
      "0h2MJmq10Z7rPHPlpUsAse",
      "Ee1ES0qaVICSo49S9m4uTZ",
      "zk60Y2QcW7AMrvFeVw9LiQ",
      "fXZcXIdFdnS0TZLs3WDx5J",
      "b5r2dSML51DJx3UKaSGKDM",
      "PYRUafRIAkSZiPBZOS7KER",
      "LsEO3LCz6e9DDNEw7PemFE",
      "ovmO3Fc0GIKm2UUIcVd2wr",
      "i5SXC3b78tl7qZg99EwEM2",
      "MMN0GviqOF4uECKlr5yTIJ",
      "Lu2vw3szZXH8nLeLFSq2B8",
      "MAikTzptrxQ3uoAJ89Spz1",
      "GZ0ARw4HbEqEGphI1txfFU",
      "i7AMtPcA5HyhUL7etyybOd",
      "T2MkfnkkWPzPTAecY9CUFB",
      "XhSVY9k89icA0MEI2baIKy",
      "RsosnZcGOf6u5fM76I8NA3",
      "Gsja9FhpJX1BEpMB5Dcnt4",
      "DL7dUwb3VJ4FesT9NOsZRY",
      "XrfUCNoyTlXPvqeWIc77kC",
      "LA7FzBs2Apxr0VagdZXX7Z",
      "E8DKTx4OqxLYirvCvBqlb7",
      "Wt8oQE1v2DRFvfF5ggsck3",
      "Z5HnhT1fbHTisjCSBLhS7P",
      "IIaPX2dwrL951i4i1ZbBs7",
      "iJFwWL0p0Ybxu4l7hJKKiL",
      "yVa2skCFJbcLmmOCtz2bNS",
      "4qv32ATesxAozSAJm7ZlIm",
      "72Mwm6POH73NPgMBTj44jU",
      "F0ti29NbyWvTZtTQGCAGCR",
      "edpRcISmOfSDtDUWeLbG0N",
      "0ONY4kH8jFTB8Vmx0N8LQT",
      "pUQaouZRRS4iA9uBWlXNMI",
      "xWUyvSMjWJy1RL3Lbz9kuv",
      "oBqVOp6Y41enFzk8lHKNdK",
      "ZiJNvLCLSnSTHRtfZjT4xw",
      "d4GxnMuLMonIFe4icu8lDx",
      "pbHsYSVYb9OsPAIN2NYYyg",
      "HEQyKZpK7iRJ9U6TcUGf4y",
      "uOjs0hfgX1vAJ0eK7HfVnu",
      "cr3OXn28TVk6PO8kYtVXUr",
      "Ls8QwyxsME28eU8ovb1cKy",
      "OrG113fbX8lCeS2xbyIWu7",
      "gckEC9ueW3f2Z6yqKG8JCc",
      "MQfIgrzQGGOaHA3Ortf0Td",
      "mLlTtDs6sXU1ahtOPubvZX",
      "PbWJLpRTtrXr0I95gNJgwd",
      "aVSlzNn5zah2kAw6KgGFco",
      "n6s22WcKB9GI6guwmWM7ME",
      "Vf5UH6z9rrqflZb9Tx3CBx",
      "6xM5OJf7TOnEYzctxnxgCA",
      "bKu9mortZx4umeRxdLeAxz",
      "yFK36oKR9lB37OxPQCLJiY",
      "Pw4QwL7vaEHVoHizdrZKww"
     ]
    }
   ],
   "version": 4
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
